import os
import pickle as pkl
from pathlib import PurePath
from typing import Union

import numpy as np

from tqdm import tqdm


def load_maps(
    path_to_maps: Union[str, PurePath],
):
    """
    Loads the maps generated by gen_saliency_maps.

    Parameters
    ----------
    path_to_maps : Union[str, PurePath]
        The path to the maps.

    Returns
    -------
    Tuple[Dict[Union[str, PurePath], Tuple[int, np.ndarray, np.ndarray]]]
        A dictionary containing the maps.
    """

    if isinstance(path_to_maps, str):
        path_to_maps = PurePath(path_to_maps)

    maps = dict()
    pbar = tqdm(
        total=os.path.getsize(path_to_maps),
        unit="B",
        unit_scale=True,
        desc="Loading maps to memory"
    )

    with open(path_to_maps, "rb") as f:
        while True:
            try:
                idx, img, map = pkl.load(f)
                maps[int(idx)] = (np.array(img), np.array(map))
            except EOFError:
                break

            pbar.update(f.tell() - pbar.n)

    pbar.close()
    return maps


def norm_map(
    map: np.ndarray
):
    """
    Normalizes the map.

    Parameters
    ----------
    map : np.ndarray
        The map to normalize.

    Returns
    -------
    np.ndarray
        The normalized map.
    """

    return (map - np.min(map)) / (np.max(map) - np.min(map))


def get_masked_image(
    img: np.ndarray,
    saliency_map: np.ndarray,
    masking_steps: int,
    method: str = "AUC"
) -> np.ndarray:
    """
    Applies the mask to the image.

    Parameters
    ----------
    img : np.ndarray
        The image with three dimensions in channel first order
        (channels, height, width).
    saliency_map : np.ndarray
        The saliency map with two dimensions, height and width.
        If the saliency map has three dimensions, the sum over
        the first dimension is calculated. The saliency map
        is then normalized.
    masking_steps : int
        The number of masking steps on the image.
        For method "AUC" this is the number of pixels from the
        saliency map to mask in the original image.
    method : str, optional
        The metric to calculate the mask for, by default "AUC"

    Returns
    -------
    np.ndarray
        The masked image.

    Raises
    ------
    NotImplementedError
        If the method is not implemented.
    """

    if len(saliency_map.shape) == 3:
        saliency_map = norm_map(np.sum(saliency_map, axis=0)).squeeze()

    r = img.shape[1]/saliency_map.shape[0]
    assert r == img.shape[2]/saliency_map.shape[1], \
        "The image and the saliency map must have the same aspect ratio."

    if method == "AUC":
        mask = np.ones((img.shape[1], img.shape[2]))

        # get the indices of the sorted saliency map in descending order
        sort_idx = np.unravel_index(
            np.argsort(-saliency_map, axis=None),
            saliency_map.shape
        )

        for i_s, j_s in zip(sort_idx[0], sort_idx[1]):
            mask[int(i_s*r):int((i_s+1)*r), int(j_s*r):int((j_s+1)*r)] = 0
            masking_steps -= 1
            if masking_steps <= 0:
                return img * mask[:, :, np.newaxis]
    else:
        raise NotImplementedError(
            f"Method {method} is not implemented."
        )
